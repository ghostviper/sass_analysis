#!/usr/bin/env python3
"""
Opportunity Discovery Script (Enhanced v2)

AI analyzes product data with market-driven frameworks to discover valuable
curation opportunities. Applies Porter's Five Forces, Blue Ocean Strategy,
and business metrics frameworks.

This script uses the complete market analysis framework defined in:
  references/curation-logic-v2.md (~1000+ lines)

For basic curation principles, see:
  references/curation-logic-basic.md (~400 lines)
"""

import os
import sys
import json
import argparse
import asyncio
from pathlib import Path
from typing import List, Dict, Any, Tuple
from dotenv import load_dotenv

# Load environment variables
script_dir = Path(__file__).parent
skill_dir = script_dir.parent
backend_dir = skill_dir.parent.parent
env_path = backend_dir / ".env"
load_dotenv(env_path)

# Import local clients
from openai_client import OpenAIClient
from api_client import BackendAPIClient


# Enhanced AI Prompt with market-driven frameworks
ENHANCED_OPPORTUNITY_DISCOVERY_PROMPT = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„äº§å“ç­–å±•ä¸“å®¶ï¼ŒåŒæ—¶å…·å¤‡æ·±åšçš„å¸‚åœºåˆ†æå’Œå•†ä¸šæ´å¯Ÿèƒ½åŠ›ã€‚

## åˆ†æç»´åº¦

### 1. äº§å“ç»´åº¦
- äº§å“ç±»å‹ã€åŠŸèƒ½ã€æŠ€æœ¯ç‰¹å¾
- ç›®æ ‡ç”¨æˆ·ã€ä½¿ç”¨åœºæ™¯
- å•†ä¸šæ¨¡å¼ã€æˆç†Ÿåº¦

### 2. å¸‚åœºç»´åº¦ï¼ˆæ–°å¢ï¼‰
- **å¸‚åœºæœºä¼š**ï¼šè¯„ä¼°å¸‚åœºè§„æ¨¡ã€è¯†åˆ«å¸‚åœºç©ºç™½
- **ç«äº‰æ ¼å±€**ï¼šåˆ†æç«äº‰å¼ºåº¦ï¼Œæ‰¾å‡ºå·®å¼‚åŒ–ç©ºé—´
- **å¢é•¿æ½œåŠ›**ï¼šè¯„ä¼°ç—…æ¯’æ€§ã€ç½‘ç»œæ•ˆåº”ã€æ‰©å±•æ€§

### 3. ç”¨æˆ·ä»·å€¼ç»´åº¦ï¼ˆæ–°å¢ï¼‰
- **ç—›ç‚¹å¼ºåº¦**ï¼šç”¨æˆ·é—®é¢˜çš„ç´§è¿«æ€§å’Œä¸¥é‡æ€§
- **ä»·å€¼ä¸»å¼ **ï¼šè§£å†³æ–¹æ¡ˆçš„æ¸…æ™°åº¦å’Œç‹¬ç‰¹æ€§
- **ROI å¯è§æ€§**ï¼šç”¨æˆ·èƒ½å¦é‡åŒ–æ”¶ç›Š

### 4. å•†ä¸šå¥åº·åº¦ç»´åº¦ï¼ˆæ–°å¢ï¼‰
- **å•ä½ç»æµ**ï¼šCACã€LTVã€Payback Period
- **ç•™å­˜è´¨é‡**ï¼šç”¨æˆ·ç²˜æ€§ã€å¤è´­ç‡
- **å®šä»·ç­–ç•¥**ï¼šä»·å€¼æ„ŸçŸ¥ä¸å®šä»·åŒ¹é…åº¦

## æœºä¼šç±»å‹ï¼ˆæ‰©å±•åˆ° 10 ç§ï¼‰

### åŸæœ‰ç±»å‹
1. **Contrastï¼ˆå¯¹æ¯”å‹ï¼‰**ï¼šé€šè¿‡å¯¹æ¯”çªå‡ºå·®å¼‚
   - ç¤ºä¾‹ï¼šé«˜æ”¶å…¥ + ä½ç²‰ä¸ = äº§å“é©±åŠ¨çš„è¯æ˜

2. **Cognitiveï¼ˆè®¤çŸ¥å‹ï¼‰**ï¼šæ”¹å˜ç”¨æˆ·è®¤çŸ¥
   - ç¤ºä¾‹ï¼šæŒ‘æˆ˜"å¿…é¡»æœ‰å¤§é‡ç”¨æˆ·æ‰èƒ½èµšé’±"çš„å‡è®¾

3. **Actionï¼ˆè¡ŒåŠ¨å‹ï¼‰**ï¼šæ¿€å‘å…·ä½“è¡ŒåŠ¨
   - ç¤ºä¾‹ï¼šæä¾›å¯ç«‹å³åº”ç”¨çš„ç­–ç•¥

4. **Nicheï¼ˆç»†åˆ†å‹ï¼‰**ï¼šèšç„¦ç‰¹å®šç»†åˆ†
   - ç¤ºä¾‹ï¼šé’ˆå¯¹ç‰¹å®šè¡Œä¸šçš„å‚ç›´å·¥å…·

### æ–°å¢ç±»å‹ï¼ˆå¸‚åœºé©±åŠ¨ï¼‰
5. **Market-Gapï¼ˆå¸‚åœºç©ºç™½å‹ï¼‰**ï¼šæœªè¢«æ»¡è¶³çš„éœ€æ±‚
   - åº”ç”¨ Blue Ocean Strategy å››è¡ŒåŠ¨æ¡†æ¶
   - è¯†åˆ«"æ¶ˆé™¤-å‡å°‘-å¢åŠ -åˆ›é€ "çš„æœºä¼š
   - ç¤ºä¾‹ï¼š"æ²¡æœ‰é’ˆå¯¹ X è¡Œä¸šçš„ Y å·¥å…·"

6. **Value-Arbitrageï¼ˆä»·å€¼å¥—åˆ©å‹ï¼‰**ï¼šé«˜ä»·å€¼ä½ä»·æ ¼
   - åº”ç”¨ pricing-strategy çš„ä»·å€¼æ„ŸçŸ¥ç†è®º
   - æ‰¾å‡ºä»·æ ¼ä¸ä»·å€¼ä¸åŒ¹é…çš„æœºä¼š
   - ç¤ºä¾‹ï¼š"ä¼ä¸šçº§åŠŸèƒ½ï¼Œä¸ªäººç‰ˆä»·æ ¼"

7. **Competitive-Weaknessï¼ˆç«å“å¼±ç‚¹å‹ï¼‰**ï¼šç«å“çŸ­æ¿
   - åº”ç”¨ Porter's Five Forces åˆ†æ
   - è¯†åˆ«ç«å“çš„ç»“æ„æ€§å¼±ç‚¹
   - ç¤ºä¾‹ï¼š"Notion å¤ªæ…¢ï¼Œæˆ‘ä»¬æ›´å¿«"

8. **Metrics-Drivenï¼ˆæŒ‡æ ‡é©±åŠ¨å‹ï¼‰**ï¼šå…³é”®æŒ‡æ ‡ä¼˜åŒ–
   - åº”ç”¨ startup-metrics-framework
   - èšç„¦å¯é‡åŒ–çš„ä¸šåŠ¡æŒ‡æ ‡æå‡
   - ç¤ºä¾‹ï¼š"æå‡ 30% è½¬åŒ–ç‡çš„å·¥å…·"

9. **Channel-Innovationï¼ˆæ¸ é“åˆ›æ–°å‹ï¼‰**ï¼šæ–°åˆ†å‘æ¸ é“
   - åº”ç”¨ launch-strategy çš„ ORB æ¡†æ¶
   - è¯†åˆ« Owned/Rented/Borrowed æ¸ é“æœºä¼š
   - ç¤ºä¾‹ï¼š"é€šè¿‡ Chrome æ‰©å±•è·å®¢"

10. **Psychology-Leverageï¼ˆå¿ƒç†æ æ†å‹ï¼‰**ï¼šè®¤çŸ¥åå·®åˆ©ç”¨
    - åº”ç”¨ marketing-psychology çš„ mental models
    - åˆ©ç”¨é”šå®šã€ç¤¾äº¤è¯æ˜ã€ç¨€ç¼ºæ€§ç­‰å¿ƒç†æ•ˆåº”
    - ç¤ºä¾‹ï¼š"ç¤¾äº¤è¯æ˜é©±åŠ¨çš„äº§å“"

## åˆ†ææ¡†æ¶åº”ç”¨

### Porter's Five Forces
- **æ–°è¿›å…¥è€…å¨èƒ**ï¼šè¿›å…¥å£å’é«˜ä½
- **ä¾›åº”å•†è®®ä»·èƒ½åŠ›**ï¼šä¾èµ–åº¦åˆ†æ
- **ä¹°å®¶è®®ä»·èƒ½åŠ›**ï¼šå®¢æˆ·é›†ä¸­åº¦
- **æ›¿ä»£å“å¨èƒ**ï¼šæ›¿ä»£æ–¹æ¡ˆè¯„ä¼°
- **è¡Œä¸šç«äº‰**ï¼šç«äº‰å¼ºåº¦åˆ¤æ–­

### Blue Ocean Strategy
- **æ¶ˆé™¤**ï¼šå“ªäº›è¡Œä¸šæ ‡é…å¯ä»¥å»æ‰ï¼Ÿ
- **å‡å°‘**ï¼šå“ªäº›åŠŸèƒ½å¯ä»¥å¤§å¹…ç®€åŒ–ï¼Ÿ
- **å¢åŠ **ï¼šå“ªäº›æ–¹é¢å¯ä»¥è¿œè¶…è¡Œä¸šæ ‡å‡†ï¼Ÿ
- **åˆ›é€ **ï¼šå“ªäº›å…¨æ–°ä»·å€¼å¯ä»¥åˆ›é€ ï¼Ÿ

### Value Theory
- **å½“å‰é—®é¢˜æˆæœ¬**ï¼šæ—¶é—´ã€é‡‘é’±ã€æ•ˆç‡æŸå¤±
- **è§£å†³æ–¹æ¡ˆä»·å€¼**ï¼šèŠ‚çœã€æ”¶ç›Šã€æ•ˆç‡æå‡
- **æ”¯ä»˜æ„æ„¿**ï¼šä»·å€¼çš„ 10-30%
- **å®šä»·ç­–ç•¥**ï¼šé”šå®šã€å¯¹æ¯”ã€åˆ†å±‚

### Business Metrics
- **SaaS**: MRR, CAC, LTV, NDR, Magic Number
- **Marketplace**: GMV, Take Rate, Liquidity
- **Consumer**: DAU/MAU, K-Factor, Retention

## æ•°æ®åˆ†æ

### æ•°æ®åº“ç»Ÿè®¡
{db_stats}

### æ¯é¢˜åˆ†å¸ƒ
{mother_theme_dist}

### äº§å“ç‰¹å¾åˆ†å¸ƒ
{product_chars}

## ä»»åŠ¡

å‘ç° {count} ä¸ªé«˜ä»·å€¼çš„ç­–å±•æœºä¼šï¼Œä¼˜å…ˆè€ƒè™‘å¸‚åœºé©±åŠ¨çš„æ–°ç±»å‹ï¼ˆ5-10ï¼‰ã€‚

## è¾“å‡ºæ ¼å¼

è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºï¼Œæ¯ä¸ªæœºä¼šåŒ…å«ï¼š

```json
[
  {{
    "opportunity_id": "unique_id_in_snake_case",
    "type": "contrast|cognitive|action|niche|market_gap|value_arbitrage|competitive_weakness|metrics_driven|channel_innovation|psychology_leverage",
    "priority": 8,
    "observation": "å…·ä½“çš„äº§å“ç‰¹å¾ç»„åˆæè¿°",
    "guidance": "AIåº”è¯¥å¯»æ‰¾ä»€ä¹ˆæ¨¡å¼/æå–ä»€ä¹ˆæ´å¯Ÿ",
    
    "market_insight": {{
      "market_size": "å°/ä¸­/å¤§",
      "competition": "ä½/ä¸­/é«˜",
      "growth_potential": "ä½/ä¸­/é«˜",
      "reasoning": "å¸‚åœºæ´å¯Ÿçš„ç†ç”±"
    }},
    
    "user_value": {{
      "pain_point": "æ ¸å¿ƒç—›ç‚¹æè¿°",
      "value_proposition": "ä»·å€¼ä¸»å¼ ",
      "roi_visibility": "ä½/ä¸­/é«˜",
      "reasoning": "ç”¨æˆ·ä»·å€¼çš„ç†ç”±"
    }},
    
    "business_logic": {{
      "unit_economics": "å¯è¡Œ/å­˜ç–‘/ä¸å¯è¡Œ",
      "retention_expectation": "ä½/ä¸­/é«˜",
      "pricing_strategy": "å®šä»·ç­–ç•¥å»ºè®®",
      "reasoning": "å•†ä¸šé€»è¾‘çš„ç†ç”±"
    }},
    
    "frameworks_applied": [
      "framework_name: specific_application"
    ],
    
    "expected_product_count": "5-10",
    "target_persona": "solo_indie_hacker|first_time_founder|serial_entrepreneur|product_manager",
    "key_insight": "è¿™ä¸ªæ¨¡å¼æ•™ç»™æˆ‘ä»¬ä»€ä¹ˆ",
    "curation_value": "ä¸ºä»€ä¹ˆè¿™ä¸ªè§’åº¦æœ‰ä»·å€¼"
  }}
]
```

## è´¨é‡æ ‡å‡†

å¥½çš„æœºä¼šå‘ç°ï¼š
- âœ… å…·ä½“ï¼šæ¸…æ™°ã€å¯è¡¡é‡çš„æ ‡å‡†
- âœ… æœ‰ä»·å€¼ï¼šæä¾›å¯æ‰§è¡Œçš„æ´å¯Ÿ
- âœ… æ•°æ®æ”¯æ’‘ï¼šé¢„è®¡5-15ä¸ªäº§å“åŒ¹é…
- âœ… æƒŠå–œæ„Ÿï¼šæŒ‘æˆ˜å‡è®¾æˆ–æ­ç¤ºéšè—æ¨¡å¼
- âœ… ç›¸å…³æ€§ï¼šæœåŠ¡ç‰¹å®šç”¨æˆ·è§’è‰²éœ€æ±‚
- âœ… å¸‚åœºæ´å¯Ÿï¼šåŒ…å«å¸‚åœºåˆ†æå’Œå•†ä¸šé€»è¾‘
- âœ… æ¡†æ¶åº”ç”¨ï¼šæ˜ç¡®ä½¿ç”¨äº†å“ªäº›åˆ†ææ¡†æ¶

é¿å…çš„æœºä¼šï¼š
- âŒ æ¨¡ç³Šï¼š"å¥½çš„äº§å“"
- âŒ æ˜¾è€Œæ˜“è§ï¼š"èµšé’±çš„äº§å“èµšé’±"
- âŒ è¿‡çª„ï¼š<3ä¸ªäº§å“
- âŒ è¿‡å®½ï¼š>30ä¸ªäº§å“
- âŒ æ— å…³ï¼šæ²¡æœ‰æ˜ç¡®ç”¨æˆ·ä»·å€¼
- âŒ ç¼ºå°‘å¸‚åœºè§†è§’ï¼šåªå…³æ³¨äº§å“ç‰¹å¾

è¯·åªè¾“å‡º JSON æ•°ç»„ï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡Šã€‚
"""


async def discover_opportunities(
    count: int = 5,
    model: str = "gpt-4o",
    api_url: str = "http://localhost:8001",
    enhanced: bool = True
) -> List[Dict[str, Any]]:
    """å‘ç°ç­–å±•æœºä¼šï¼ˆå¢å¼ºç‰ˆï¼‰"""
    
    # Get data from backend API
    async with BackendAPIClient(base_url=api_url) as api:
        db_stats = await api.get_db_stats()
        mother_theme_dist = await api.get_mother_theme_distribution()
        product_chars = await api.get_product_characteristics()
    
    # Format data for prompt
    db_stats_text = json.dumps(db_stats, indent=2, ensure_ascii=False)
    mother_theme_text = json.dumps(mother_theme_dist, indent=2, ensure_ascii=False)
    product_chars_text = json.dumps(product_chars, indent=2, ensure_ascii=False)
    
    # Build prompt (use enhanced version)
    prompt = ENHANCED_OPPORTUNITY_DISCOVERY_PROMPT.format(
        count=count,
        db_stats=db_stats_text,
        mother_theme_dist=mother_theme_text,
        product_chars=product_chars_text
    )
    
    # Call AI
    async with OpenAIClient(model=model) as ai:
        response = await ai.chat(
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„äº§å“ç­–å±•ä¸“å®¶ï¼ŒåŒæ—¶å…·å¤‡æ·±åšçš„å¸‚åœºåˆ†æå’Œå•†ä¸šæ´å¯Ÿèƒ½åŠ›ã€‚ä½ æ“…é•¿åº”ç”¨ Porter's Five Forcesã€Blue Ocean Strategyã€Value Theory ç­‰æ¡†æ¶æ¥å‘ç°æœ‰ä»·å€¼çš„ç­–å±•è§’åº¦ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.8  # Higher temperature for more creative discovery
        )
    
    # Parse JSON response
    opportunities = parse_json_response(response)
    return opportunities


def parse_json_response(response: str) -> List[Dict[str, Any]]:
    """ä»AIå“åº”ä¸­è§£æJSON"""
    try:
        # Try direct parse
        return json.loads(response)
    except json.JSONDecodeError:
        pass
    
    # Try to extract from code block
    try:
        if "```json" in response:
            start = response.find("```json") + 7
            end = response.find("```", start)
            json_str = response[start:end].strip()
            return json.loads(json_str)
        elif "```" in response:
            start = response.find("```") + 3
            end = response.find("```", start)
            json_str = response[start:end].strip()
            return json.loads(json_str)
    except (json.JSONDecodeError, ValueError):
        pass
    
    # Try to find JSON array in response
    try:
        start = response.find("[")
        end = response.rfind("]") + 1
        if start >= 0 and end > start:
            json_str = response[start:end]
            return json.loads(json_str)
    except (json.JSONDecodeError, ValueError):
        pass
    
    raise ValueError("Failed to parse JSON from AI response")



def format_opportunity_output(opportunities: List[Dict[str, Any]]) -> str:
    """æ ¼å¼åŒ–æœºä¼šè¾“å‡ºï¼ˆå¢å¼ºç‰ˆï¼‰"""
    output = []
    output.append("=" * 80)
    output.append(f"å‘ç° {len(opportunities)} ä¸ªç­–å±•æœºä¼šï¼ˆå¢å¼ºç‰ˆ v2ï¼‰")
    output.append("=" * 80)
    output.append("")
    
    for i, opp in enumerate(opportunities, 1):
        output.append(f"## æœºä¼š {i}: {opp.get('opportunity_id', 'unknown')}")
        output.append("")
        output.append(f"**ç±»å‹**: {opp.get('type', 'unknown')}")
        output.append(f"**ä¼˜å…ˆçº§**: {opp.get('priority', 5)}/10")
        output.append(f"**ç›®æ ‡ç”¨æˆ·**: {opp.get('target_persona', 'unknown')}")
        output.append(f"**é¢„è®¡äº§å“æ•°**: {opp.get('expected_product_count', 'unknown')}")
        output.append("")
        
        # Market Insight (æ–°å¢)
        if 'market_insight' in opp:
            mi = opp['market_insight']
            output.append(f"**å¸‚åœºæ´å¯Ÿ**:")
            output.append(f"  - å¸‚åœºè§„æ¨¡: {mi.get('market_size', 'unknown')}")
            output.append(f"  - ç«äº‰å¼ºåº¦: {mi.get('competition', 'unknown')}")
            output.append(f"  - å¢é•¿æ½œåŠ›: {mi.get('growth_potential', 'unknown')}")
            output.append(f"  - ç†ç”±: {mi.get('reasoning', '')}")
            output.append("")
        
        # User Value (æ–°å¢)
        if 'user_value' in opp:
            uv = opp['user_value']
            output.append(f"**ç”¨æˆ·ä»·å€¼**:")
            output.append(f"  - æ ¸å¿ƒç—›ç‚¹: {uv.get('pain_point', '')}")
            output.append(f"  - ä»·å€¼ä¸»å¼ : {uv.get('value_proposition', '')}")
            output.append(f"  - ROIå¯è§æ€§: {uv.get('roi_visibility', 'unknown')}")
            output.append(f"  - ç†ç”±: {uv.get('reasoning', '')}")
            output.append("")
        
        # Business Logic (æ–°å¢)
        if 'business_logic' in opp:
            bl = opp['business_logic']
            output.append(f"**å•†ä¸šé€»è¾‘**:")
            output.append(f"  - å•ä½ç»æµ: {bl.get('unit_economics', 'unknown')}")
            output.append(f"  - ç•™å­˜é¢„æœŸ: {bl.get('retention_expectation', 'unknown')}")
            output.append(f"  - å®šä»·ç­–ç•¥: {bl.get('pricing_strategy', '')}")
            output.append(f"  - ç†ç”±: {bl.get('reasoning', '')}")
            output.append("")
        
        # Frameworks Applied (æ–°å¢)
        if 'frameworks_applied' in opp:
            output.append(f"**åº”ç”¨æ¡†æ¶**:")
            for framework in opp['frameworks_applied']:
                output.append(f"  - {framework}")
            output.append("")
        
        output.append(f"**è§‚å¯Ÿç»´åº¦**:")
        output.append(f"```")
        output.append(opp.get('observation', ''))
        output.append(f"```")
        output.append("")
        output.append(f"**æŒ‡å¼•**:")
        output.append(f"```")
        output.append(opp.get('guidance', ''))
        output.append(f"```")
        output.append("")
        output.append(f"**æ ¸å¿ƒæ´å¯Ÿ**: {opp.get('key_insight', '')}")
        output.append("")
        output.append(f"**ç­–å±•ä»·å€¼**: {opp.get('curation_value', '')}")
        output.append("")
        output.append("-" * 80)
        output.append("")
    
    return "\n".join(output)


def analyze_opportunity_types(opportunities: List[Dict[str, Any]]) -> Dict[str, Any]:
    """åˆ†ææœºä¼šç±»å‹åˆ†å¸ƒ"""
    type_counts = {}
    for opp in opportunities:
        opp_type = opp.get('type', 'unknown')
        type_counts[opp_type] = type_counts.get(opp_type, 0) + 1
    
    # Categorize into old vs new types
    old_types = ['contrast', 'cognitive', 'action', 'niche']
    new_types = ['market_gap', 'value_arbitrage', 'competitive_weakness', 
                 'metrics_driven', 'channel_innovation', 'psychology_leverage']
    
    old_count = sum(type_counts.get(t, 0) for t in old_types)
    new_count = sum(type_counts.get(t, 0) for t in new_types)
    
    return {
        'type_counts': type_counts,
        'old_types_count': old_count,
        'new_types_count': new_count,
        'total': len(opportunities)
    }


async def main():
    parser = argparse.ArgumentParser(description="Discover curation opportunities using AI (Enhanced v2)")
    parser.add_argument("--count", "-c", type=int, default=5, help="Number of opportunities to discover")
    parser.add_argument("--model", "-m", help="AI model to use (default from env)")
    parser.add_argument("--output", "-o", help="Output file path (JSON)")
    parser.add_argument("--api-url", default="http://localhost:8001", help="Backend API URL")
    
    args = parser.parse_args()
    
    # Use model from env if not specified
    model = args.model or os.getenv("OPENAI_MODEL", "gpt-4o")
    
    print(f"ğŸ” Discovering {args.count} curation opportunities (Enhanced v2)...")
    print(f"ğŸ¤– Using model: {model}")
    print(f"ğŸ”— API URL: {args.api_url}")
    print(f"âœ¨ New features:")
    print(f"   - 10 opportunity types (6 new market-driven types)")
    print(f"   - Market insight analysis")
    print(f"   - User value assessment")
    print(f"   - Business logic evaluation")
    print(f"   - Framework application tracking")
    print()
    
    try:
        # Discover opportunities
        opportunities = await discover_opportunities(
            count=args.count,
            model=model,
            api_url=args.api_url,
            enhanced=True
        )
        
        # Analyze types
        type_analysis = analyze_opportunity_types(opportunities)
        
        print(f"ğŸ“Š Opportunity Type Distribution:")
        print(f"   Old types (1-4): {type_analysis['old_types_count']}")
        print(f"   New types (5-10): {type_analysis['new_types_count']}")
        print(f"   Details: {json.dumps(type_analysis['type_counts'], indent=2)}")
        print()
        
        # Format output
        formatted = format_opportunity_output(opportunities)
        print(formatted)
        
        # Determine output path
        if args.output:
            # Create output directory in skill folder
            output_dir = skill_dir / "output"
            output_dir.mkdir(exist_ok=True)
            
            # Use provided filename or generate one
            if args.output.endswith('.json'):
                output_filename = args.output
            else:
                output_filename = f"{args.output}.json"
            
            output_path = output_dir / output_filename
        else:
            # Generate default filename with timestamp
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_dir = skill_dir / "output"
            output_dir.mkdir(exist_ok=True)
            output_path = output_dir / f"opportunities_{timestamp}.json"
        
        # Save JSON
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(opportunities, f, indent=2, ensure_ascii=False)
        
        # Also save formatted text
        text_path = output_path.with_suffix('.txt')
        text_path.write_text(formatted, encoding='utf-8')
        
        # Save analysis
        analysis_path = output_path.with_name(output_path.stem + '_analysis.json')
        with open(analysis_path, 'w', encoding='utf-8') as f:
            json.dump(type_analysis, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… Opportunities saved to:")
        print(f"   JSON: {output_path.relative_to(backend_dir)}")
        print(f"   Text: {text_path.relative_to(backend_dir)}")
        print(f"   Analysis: {analysis_path.relative_to(backend_dir)}")
        
        print()
        print("âœ¨ Discovery complete!")
        print()
        print("Next steps:")
        print("1. Review the discovered opportunities")
        print("2. Note the market insights and business logic")
        print("3. Select interesting ones to generate templates:")
        print("   python scripts/generate_template.py \\")
        print("     --observation \"<observation>\" \\")
        print("     --guidance \"<guidance>\" \\")
        print("     --count 2")
        
    except Exception as e:
        print(f"âŒ Error: {str(e)}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
