"""
åŒæ­¥æ•°æ®åˆ°å‘é‡åº“

ç”¨æ³•:
    python scripts/sync_vectors.py --all        # åŒæ­¥æ‰€æœ‰æ•°æ®
    python scripts/sync_vectors.py --products   # åªåŒæ­¥äº§å“
    python scripts/sync_vectors.py --categories # åªåŒæ­¥èµ›é“
    python scripts/sync_vectors.py --full       # å…¨é‡åŒæ­¥ï¼ˆæ¸…ç©ºåé‡å»ºï¼‰
    python scripts/sync_vectors.py --stats      # æŸ¥çœ‹ç»Ÿè®¡
"""

import asyncio
import argparse
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° path
sys.path.insert(0, str(Path(__file__).parent.parent))

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv()

from sqlalchemy import select
from database.db import AsyncSessionLocal
from database.models import (
    Startup, 
    LandingPageAnalysis, 
    ProductSelectionAnalysis,
    CategoryAnalysis,
    ComprehensiveAnalysis
)
from services.vector_store import vector_store


# ============================================================================
# äº§å“å‘é‡åŒ–
# ============================================================================

def build_product_text(startup, landing, selection, comprehensive) -> str:
    """æ„å»ºäº§å“çš„å‘é‡åŒ–æ–‡æœ¬"""
    parts = [
        f"äº§å“: {startup.name}",
    ]
    
    if startup.description:
        parts.append(f"æè¿°: {startup.description}")
    
    if startup.category:
        parts.append(f"ç±»ç›®: {startup.category}")
    
    # Landing page åˆ†ææ•°æ®
    if landing:
        if landing.headline_text:
            parts.append(f"å®šä½: {landing.headline_text}")
        
        if landing.target_audience:
            audiences = landing.target_audience if isinstance(landing.target_audience, list) else []
            if audiences:
                parts.append(f"ç›®æ ‡ç”¨æˆ·: {', '.join(audiences[:5])}")
        
        if landing.use_cases:
            cases = landing.use_cases if isinstance(landing.use_cases, list) else []
            if cases:
                parts.append(f"ä½¿ç”¨åœºæ™¯: {', '.join(cases[:5])}")
        
        if landing.core_features:
            features = landing.core_features if isinstance(landing.core_features, list) else []
            if features:
                parts.append(f"æ ¸å¿ƒåŠŸèƒ½: {', '.join(features[:5])}")
        
        if landing.pain_points:
            pains = landing.pain_points if isinstance(landing.pain_points, list) else []
            if pains:
                parts.append(f"è§£å†³ç—›ç‚¹: {', '.join(pains[:3])}")
        
        if landing.value_propositions:
            props = landing.value_propositions if isinstance(landing.value_propositions, list) else []
            if props:
                parts.append(f"ä»·å€¼ä¸»å¼ : {', '.join(props[:3])}")
    
    # é€‰å“åˆ†ææ•°æ®
    if selection:
        if selection.tech_complexity_level:
            parts.append(f"æŠ€æœ¯å¤æ‚åº¦: {selection.tech_complexity_level}")
        if selection.target_customer:
            parts.append(f"ç›®æ ‡å®¢æˆ·: {selection.target_customer}")
        if selection.pricing_model:
            parts.append(f"å®šä»·æ¨¡å¼: {selection.pricing_model}")
        if selection.growth_driver:
            parts.append(f"å¢é•¿é©±åŠ¨: {selection.growth_driver}")
        if selection.ai_dependency_level:
            parts.append(f"AIä¾èµ–: {selection.ai_dependency_level}")
    
    # ç»¼åˆåˆ†ææ‘˜è¦
    if comprehensive and comprehensive.analysis_summary:
        summary = comprehensive.analysis_summary
        if isinstance(summary, dict):
            if summary.get("one_liner"):
                parts.append(f"ä¸€å¥è¯æ€»ç»“: {summary['one_liner']}")
            if summary.get("strengths"):
                strengths = summary["strengths"][:2] if isinstance(strengths, list) else []
                if strengths:
                    parts.append(f"ä¼˜åŠ¿: {', '.join(strengths)}")
    
    return "\n".join(parts)


def build_product_metadata(startup, landing, selection, comprehensive) -> dict:
    """æ„å»ºäº§å“çš„å…ƒæ•°æ®ï¼ˆç”¨äºè¿‡æ»¤ï¼‰"""
    meta = {
        "startup_id": startup.id,
        "name": startup.name,
        "slug": startup.slug,
    }
    
    if startup.category:
        meta["category"] = startup.category
    
    if startup.revenue_30d is not None:
        meta["revenue_30d"] = float(startup.revenue_30d)
    
    if selection:
        if selection.tech_complexity_level:
            meta["tech_complexity"] = selection.tech_complexity_level
        if selection.target_customer:
            meta["target_customer"] = selection.target_customer
        if selection.ai_dependency_level:
            meta["ai_dependency"] = selection.ai_dependency_level
        if selection.individual_dev_suitability is not None:
            meta["suitability_score"] = float(selection.individual_dev_suitability)
        if selection.pricing_model:
            meta["pricing_model"] = selection.pricing_model
    
    if comprehensive:
        if comprehensive.overall_recommendation is not None:
            meta["recommendation_score"] = float(comprehensive.overall_recommendation)
    
    return meta


async def load_products():
    """ä»æ•°æ®åº“åŠ è½½äº§å“æ•°æ®"""
    async with AsyncSessionLocal() as db:
        # åŠ è½½æ‰€æœ‰äº§å“
        result = await db.execute(select(Startup))
        startups = {s.id: s for s in result.scalars().all()}
        
        # åŠ è½½ landing page åˆ†æ
        result = await db.execute(select(LandingPageAnalysis))
        landings = {l.startup_id: l for l in result.scalars().all()}
        
        # åŠ è½½é€‰å“åˆ†æ
        result = await db.execute(select(ProductSelectionAnalysis))
        selections = {s.startup_id: s for s in result.scalars().all()}
        
        # åŠ è½½ç»¼åˆåˆ†æ
        result = await db.execute(select(ComprehensiveAnalysis))
        comprehensives = {c.startup_id: c for c in result.scalars().all()}
        
        products = []
        for startup_id, startup in startups.items():
            landing = landings.get(startup_id)
            selection = selections.get(startup_id)
            comprehensive = comprehensives.get(startup_id)
            products.append((startup, landing, selection, comprehensive))
        
        return products


async def sync_products(full: bool = False):
    """åŒæ­¥äº§å“åˆ°å‘é‡åº“"""
    print("\nğŸ“¦ [äº§å“] åŠ è½½æ•°æ®...")
    products = await load_products()
    print(f"   æ‰¾åˆ° {len(products)} ä¸ªäº§å“")
    
    if full:
        print("ğŸ—‘ï¸  æ¸…ç©ºç°æœ‰äº§å“å‘é‡...")
        vector_store.delete_all(namespace="products")
    
    print("ğŸ”„ ç”Ÿæˆå‘é‡...")
    
    batch_size = 20
    total_synced = 0
    
    for i in range(0, len(products), batch_size):
        batch = products[i:i + batch_size]
        
        texts = []
        items = []
        for startup, landing, selection, comprehensive in batch:
            text = build_product_text(startup, landing, selection, comprehensive)
            metadata = build_product_metadata(startup, landing, selection, comprehensive)
            texts.append(text)
            items.append({
                "id": f"product_{startup.id}",
                "metadata": metadata
            })
        
        try:
            embeddings = await vector_store.get_embeddings_batch(texts)
        except Exception as e:
            print(f"   âš ï¸ Embedding å¤±è´¥: {e}")
            continue
        
        vectors = []
        for item, embedding in zip(items, embeddings):
            item["values"] = embedding
            vectors.append(item)
        
        try:
            count = vector_store.upsert(vectors, namespace="products")
            total_synced += count
            print(f"   âœ“ äº§å“å·²åŒæ­¥ {total_synced}/{len(products)}")
        except Exception as e:
            print(f"   âš ï¸ ä¸Šä¼ å¤±è´¥: {e}")
    
    print(f"âœ… äº§å“åŒæ­¥å®Œæˆï¼Œå…± {total_synced} æ¡")
    return total_synced


# ============================================================================
# èµ›é“å‘é‡åŒ–
# ============================================================================

def build_category_text(category: CategoryAnalysis) -> str:
    """æ„å»ºèµ›é“çš„å‘é‡åŒ–æ–‡æœ¬"""
    parts = [
        f"èµ›é“: {category.category}",
    ]
    
    if category.market_type:
        parts.append(f"å¸‚åœºç±»å‹: {category.market_type}")
    
    if category.market_type_reason:
        parts.append(f"å¸‚åœºç‰¹å¾: {category.market_type_reason}")
    
    if category.total_projects:
        parts.append(f"äº§å“æ•°é‡: {category.total_projects}")
    
    if category.total_revenue:
        parts.append(f"æ€»æ”¶å…¥: ${category.total_revenue:,.0f}")
    
    if category.median_revenue:
        parts.append(f"ä¸­ä½æ•°æ”¶å…¥: ${category.median_revenue:,.0f}")
    
    if category.gini_coefficient is not None:
        gini = category.gini_coefficient
        if gini < 0.3:
            distribution = "æ”¶å…¥åˆ†å¸ƒå‡åŒ€ï¼Œç«äº‰æ¿€çƒˆ"
        elif gini < 0.5:
            distribution = "æ”¶å…¥åˆ†å¸ƒé€‚ä¸­"
        else:
            distribution = "æ”¶å…¥é›†ä¸­åœ¨å¤´éƒ¨ï¼Œå­˜åœ¨å¯¡å¤´"
        parts.append(f"æ”¶å…¥åˆ†å¸ƒ: {distribution} (åŸºå°¼ç³»æ•° {gini:.2f})")
    
    if category.top10_revenue_share:
        parts.append(f"å¤´éƒ¨é›†ä¸­åº¦: TOP10å æ¯” {category.top10_revenue_share:.1f}%")
    
    return "\n".join(parts)


def build_category_metadata(category: CategoryAnalysis) -> dict:
    """æ„å»ºèµ›é“çš„å…ƒæ•°æ®"""
    meta = {
        "category": category.category,
        "category_id": category.id,
    }
    
    if category.market_type:
        meta["market_type"] = category.market_type
    
    if category.total_projects:
        meta["total_projects"] = category.total_projects
    
    if category.total_revenue:
        meta["total_revenue"] = float(category.total_revenue)
    
    if category.median_revenue:
        meta["median_revenue"] = float(category.median_revenue)
    
    if category.gini_coefficient is not None:
        meta["gini_coefficient"] = float(category.gini_coefficient)
    
    return meta


async def load_categories():
    """ä»æ•°æ®åº“åŠ è½½èµ›é“æ•°æ®ï¼ˆæ¯ä¸ªèµ›é“å–æœ€æ–°ä¸€æ¡ï¼‰"""
    async with AsyncSessionLocal() as db:
        # è·å–æ‰€æœ‰èµ›é“åˆ†æï¼ŒæŒ‰æ—¥æœŸé™åº
        result = await db.execute(
            select(CategoryAnalysis)
            .order_by(CategoryAnalysis.category, CategoryAnalysis.analysis_date.desc())
        )
        all_analyses = result.scalars().all()
        
        # æ¯ä¸ªèµ›é“åªä¿ç•™æœ€æ–°çš„
        latest = {}
        for analysis in all_analyses:
            if analysis.category not in latest:
                latest[analysis.category] = analysis
        
        return list(latest.values())


async def sync_categories(full: bool = False):
    """åŒæ­¥èµ›é“åˆ°å‘é‡åº“"""
    print("\nğŸ“¦ [èµ›é“] åŠ è½½æ•°æ®...")
    categories = await load_categories()
    print(f"   æ‰¾åˆ° {len(categories)} ä¸ªèµ›é“")
    
    if not categories:
        print("   âš ï¸ æ²¡æœ‰èµ›é“æ•°æ®ï¼Œè·³è¿‡")
        return 0
    
    if full:
        print("ğŸ—‘ï¸  æ¸…ç©ºç°æœ‰èµ›é“å‘é‡...")
        vector_store.delete_all(namespace="categories")
    
    print("ğŸ”„ ç”Ÿæˆå‘é‡...")
    
    texts = []
    items = []
    for cat in categories:
        text = build_category_text(cat)
        metadata = build_category_metadata(cat)
        texts.append(text)
        items.append({
            "id": f"category_{cat.category}",
            "metadata": metadata
        })
    
    try:
        embeddings = await vector_store.get_embeddings_batch(texts)
    except Exception as e:
        print(f"   âš ï¸ Embedding å¤±è´¥: {e}")
        return 0
    
    vectors = []
    for item, embedding in zip(items, embeddings):
        item["values"] = embedding
        vectors.append(item)
    
    try:
        count = vector_store.upsert(vectors, namespace="categories")
        print(f"âœ… èµ›é“åŒæ­¥å®Œæˆï¼Œå…± {count} æ¡")
        return count
    except Exception as e:
        print(f"   âš ï¸ ä¸Šä¼ å¤±è´¥: {e}")
        return 0


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

async def show_stats():
    """æ˜¾ç¤ºå‘é‡åº“ç»Ÿè®¡"""
    if not vector_store.enabled:
        print("âŒ å‘é‡æœåŠ¡æœªå¯ç”¨")
        return
    
    stats = vector_store.stats()
    print("\nğŸ“Š å‘é‡åº“ç»Ÿè®¡:")
    print(f"   æ€»å‘é‡æ•°: {stats.get('total_vector_count', 0)}")
    
    namespaces = stats.get("namespaces", {})
    if namespaces:
        for ns, info in namespaces.items():
            print(f"   - {ns}: {info.get('vector_count', 0)} æ¡")
    else:
        print("   (æš‚æ— æ•°æ®)")


async def main():
    parser = argparse.ArgumentParser(description="åŒæ­¥æ•°æ®åˆ°å‘é‡åº“")
    parser.add_argument("--all", action="store_true", help="åŒæ­¥æ‰€æœ‰æ•°æ®")
    parser.add_argument("--products", action="store_true", help="åªåŒæ­¥äº§å“")
    parser.add_argument("--categories", action="store_true", help="åªåŒæ­¥èµ›é“")
    parser.add_argument("--full", action="store_true", help="å…¨é‡åŒæ­¥ï¼ˆæ¸…ç©ºåé‡å»ºï¼‰")
    parser.add_argument("--stats", action="store_true", help="æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯")
    args = parser.parse_args()
    
    if not vector_store.enabled:
        print("âŒ å‘é‡æœåŠ¡æœªå¯ç”¨ï¼Œè¯·é…ç½® PINECONE_API_KEY")
        return
    
    if args.stats:
        await show_stats()
        return
    
    # é»˜è®¤åŒæ­¥æ‰€æœ‰
    sync_all = args.all or (not args.products and not args.categories)
    
    total = 0
    
    if sync_all or args.products:
        total += await sync_products(full=args.full)
    
    if sync_all or args.categories:
        total += await sync_categories(full=args.full)
    
    print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼Œå…±åŒæ­¥ {total} æ¡å‘é‡")
    await show_stats()


if __name__ == "__main__":
    asyncio.run(main())
