# Claude API Key for Agent SDK
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Optional: Custom Claude API endpoint (for third-party proxies)
# Note: Do NOT include /v1 suffix - SDK will add it automatically
# ANTHROPIC_BASE_URL=https://api.anthropic.com

# Optional: Claude Code CLI path (auto-detected if not specified)
# CLAUDE_CLI_PATH=/path/to/claude

# Claude Model Configuration - 4 model environment variables
# ANTHROPIC_MODEL: Main model used for requests
# ANTHROPIC_DEFAULT_SONNET_MODEL: Default Sonnet model
# ANTHROPIC_DEFAULT_HAIKU_MODEL: Default Haiku model (for fast/simple tasks)
# ANTHROPIC_DEFAULT_OPUS_MODEL: Default Opus model (for complex tasks)
ANTHROPIC_MODEL=claude-sonnet-4-5-20250929
ANTHROPIC_DEFAULT_SONNET_MODEL=claude-sonnet-4-5-20250929
ANTHROPIC_DEFAULT_HAIKU_MODEL=claude-sonnet-4-5-20250929
ANTHROPIC_DEFAULT_OPUS_MODEL=claude-opus-4-5-20251101

# OpenAI API Key for Landing Page Analysis
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4o

# Database
# PostgreSQL/Supabase (recommended for production)
DATABASE_URL=postgresql://postgres:password@localhost:54322/postgres
# MySQL
# DATABASE_URL=mysql://user:password@localhost:3306/sass_analysis
# SQLite (for development)
# DATABASE_URL=sqlite:///data/sass_analysis.db

# Database pool settings (PostgreSQL/MySQL only)
DB_POOL_SIZE=10
DB_MAX_OVERFLOW=20
DB_POOL_TIMEOUT=30
DB_POOL_RECYCLE=3600
DB_ECHO=false

# Server
HOST=0.0.0.0
PORT=8001
DEBUG=true

# Proxy (optional, for accessing external APIs)
# HTTP_PROXY=http://127.0.0.1:7890
# HTTPS_PROXY=http://127.0.0.1:7890

# ============================================================================
# Channel Search API Keys
# ============================================================================

# Google Custom Search API (Free: 100 queries/day)
# Get API Key: https://console.cloud.google.com/apis/credentials
# Create Search Engine: https://programmablesearchengine.google.com/
GOOGLE_CUSTOM_SEARCH_API_KEY=your_google_api_key_here
GOOGLE_CUSTOM_SEARCH_ENGINE_ID=your_search_engine_id_here

# SerpAPI (Commercial: $50/month for 5000 searches)
# Sign up: https://serpapi.com/
SERPAPI_API_KEY=your_serpapi_key_here

# Tavily Search API (AI-optimized search)
# Sign up: https://tavily.com/
TAVILY_API_KEY=your_tavily_key_here

# Reddit API (Optional: for authenticated access, 100 req/min)
# Create app: https://www.reddit.com/prefs/apps
# Leave empty to use anonymous mode (10 req/min)
REDDIT_CLIENT_ID=
REDDIT_CLIENT_SECRET=
REDDIT_USER_AGENT=SaaSAnalysis/1.0

# Search Configuration
# Choose default Google search backend: custom, serpapi, or tavily
GOOGLE_SEARCH_BACKEND=custom
# Enable search result caching (reduces API calls)
SEARCH_CACHE_ENABLED=true
SEARCH_CACHE_TTL=3600

# ============================================================================
# Redis Configuration (for chat session storage)
# ============================================================================

# Redis connection URL
# Format: redis://[[username:]password@]host[:port][/database]
REDIS_URL=redis://localhost:6379/0

# Enable/disable Redis (if disabled, falls back to direct SQLite writes)
REDIS_ENABLED=true

# Redis password (optional)
# REDIS_PASSWORD=your_redis_password

# Connection pool settings
REDIS_MAX_CONNECTIONS=20

# TTL settings (in seconds)
REDIS_SESSION_TTL=604800      # 7 days
REDIS_MESSAGE_TTL=604800      # 7 days

# Sync settings
SYNC_INTERVAL_SECONDS=60      # How often to sync dirty sessions to SQLite
SYNC_BATCH_SIZE=100           # Max sessions to sync per batch
SYNC_ON_DONE=true             # Sync immediately after stream completes

# Fallback behavior
REDIS_FALLBACK_ON_ERROR=true  # Fall back to SQLite if Redis fails
